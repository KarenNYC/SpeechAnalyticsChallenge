{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from pysndfx import AudioEffectsChain\n",
    "import numpy as np\n",
    "import math\n",
    "import python_speech_features\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "\n",
    "import IPython\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the file, Return audio time series (y) and sampling rate (sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_name):\n",
    "    sample_file = file_name\n",
    "    sample_path = 'Samples/'+ sample_file\n",
    "\n",
    "    # generating audio time series and a sampling rate (int)\n",
    "    y, sr = librosa.load(sample_path)\n",
    "\n",
    "    return y, sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Reduction using four different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_noise_power(y, sr):\n",
    "\n",
    "    cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "\n",
    "    threshold_h = round(np.median(cent))*1.5\n",
    "    threshold_l = round(np.median(cent))*0.1\n",
    "\n",
    "    less_noise = AudioEffectsChain().lowshelf(gain=-30.0, frequency=threshold_l, slope=0.8).highshelf(gain=-12.0, frequency=threshold_h, slope=0.5)#.limiter(gain=6.0)\n",
    "    y_clean = less_noise(y)\n",
    "\n",
    "    return y_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_noise_median(y, sr):\n",
    "    y = sp.signal.medfilt(y,3)\n",
    "    return (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_noise_mfcc_down(y, sr):\n",
    "\n",
    "    hop_length = 512\n",
    "\n",
    "    ## mfcc\n",
    "    mfcc = python_speech_features.base.mfcc(y)\n",
    "    mfcc = python_speech_features.base.logfbank(y)\n",
    "    mfcc = python_speech_features.base.lifter(mfcc)\n",
    "\n",
    "    sum_of_squares = []\n",
    "    index = -1\n",
    "    for r in mfcc:\n",
    "        sum_of_squares.append(0)\n",
    "        index = index + 1\n",
    "        for n in r:\n",
    "            sum_of_squares[index] = sum_of_squares[index] + n**2\n",
    "\n",
    "    strongest_frame = sum_of_squares.index(max(sum_of_squares))\n",
    "    hz = python_speech_features.base.mel2hz(mfcc[strongest_frame])\n",
    "\n",
    "    max_hz = max(hz)\n",
    "    min_hz = min(hz)\n",
    "\n",
    "    speech_booster = AudioEffectsChain().highshelf(frequency=min_hz*(-1)*1.2, gain=-12.0, slope=0.6).limiter(gain=8.0)\n",
    "    y_speach_boosted = speech_booster(y)\n",
    "\n",
    "    return (y_speach_boosted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_noise_mfcc_up(y, sr):\n",
    "\n",
    "    hop_length = 512\n",
    "\n",
    "    ## mfcc\n",
    "    mfcc = python_speech_features.base.mfcc(y)\n",
    "    mfcc = python_speech_features.base.logfbank(y)\n",
    "    mfcc = python_speech_features.base.lifter(mfcc)\n",
    "\n",
    "    sum_of_squares = []\n",
    "    index = -1\n",
    "    for r in mfcc:\n",
    "        sum_of_squares.append(0)\n",
    "        index = index + 1\n",
    "        for n in r:\n",
    "            sum_of_squares[index] = sum_of_squares[index] + n**2\n",
    "\n",
    "    strongest_frame = sum_of_squares.index(max(sum_of_squares))\n",
    "    hz = python_speech_features.base.mel2hz(mfcc[strongest_frame])\n",
    "\n",
    "    max_hz = max(hz)\n",
    "    min_hz = min(hz)\n",
    "\n",
    "    speech_booster = AudioEffectsChain().lowshelf(frequency=min_hz*(-1), gain=12.0, slope=0.5)#.highshelf(frequency=min_hz*(-1)*1.2, gain=-12.0, slope=0.5)#.limiter(gain=8.0)\n",
    "    y_speach_boosted = speech_booster(y)\n",
    "\n",
    "    return (y_speach_boosted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trim Silence and Enhance the Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_silence(y):\n",
    "    y_trimmed, index = librosa.effects.trim(y, top_db=20, frame_length=2, hop_length=500)\n",
    "    trimmed_length = librosa.get_duration(y) - librosa.get_duration(y_trimmed)\n",
    "\n",
    "    return y_trimmed, trimmed_length\n",
    "\n",
    "def enhance(y):\n",
    "    apply_audio_effects = AudioEffectsChain().lowshelf(gain=10.0, frequency=260, slope=0.1).reverb(reverberance=25, hf_damping=5, room_scale=5, stereo_depth=50, pre_delay=20, wet_gain=0, wet_only=False)#.normalize()\n",
    "    y_enhanced = apply_audio_effects(y)\n",
    "\n",
    "    return y_enhanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output in .wav format (TBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_file(destination ,filename, y, sr, ext=\"\"):\n",
    "    destination = destination + filename[:-4] + ext + '.wav'\n",
    "    #maxv = np.iinfo(np.int16).max\n",
    "    librosa.output.write_wav(destination, y, sr) #(y * maxv).astype(np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the sample files and Get the Results\n",
    "1. Load the sample files\n",
    "    \n",
    "2. Reduce Noise\n",
    "    \n",
    "3. Trim Silence\n",
    "    \n",
    "4. Save the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('Samples/Sample_Results'):\n",
    "    os.makedirs('Samples/Sample_Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ['A1_with_noise.wav','A2_with_noise.wav','MPF check restaurant surroundings.m4a']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chuanyu/opt/anaconda3/envs/py3.5/lib/python3.5/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    }
   ],
   "source": [
    "for s in samples:\n",
    "    # reading a file\n",
    "    filename = s\n",
    "    y, sr = read_file(filename)\n",
    "\n",
    "    # reducing noise using db power\n",
    "    y_reduced_power = reduce_noise_power(y, sr)\n",
    "    y_reduced_mfcc_up = reduce_noise_mfcc_up(y, sr)\n",
    "    y_reduced_mfcc_down = reduce_noise_mfcc_down(y, sr)\n",
    "    y_reduced_median = reduce_noise_median(y, sr)\n",
    "\n",
    "    # trimming silences\n",
    "    y_reduced_power, time_trimmed = trim_silence(y_reduced_power)\n",
    "    # print (time_trimmed)\n",
    "\n",
    "    ###y_reduced_centroid_s, time_trimmed = trim_silence(y_reduced_centroid_s)\n",
    "    # print (time_trimmed)\n",
    "\n",
    "    y_reduced_power, time_trimmed = trim_silence(y_reduced_power)\n",
    "    # print (time_trimmed)\n",
    "\n",
    "    ###y_reduced_centroid_mb, time_trimmed = trim_silence(y_reduced_centroid_mb)\n",
    "    # print (time_trimmed)\n",
    "\n",
    "    y_reduced_mfcc_up, time_trimmed = trim_silence(y_reduced_mfcc_up)\n",
    "    # print (time_trimmed)\n",
    "\n",
    "    y_reduced_mfcc_down, time_trimmed = trim_silence(y_reduced_mfcc_down)\n",
    "    # print (time_trimmed)\n",
    "\n",
    "    y_reduced_median, time_trimmed = trim_silence(y_reduced_median)\n",
    "  \n",
    "    # generating output file [1]\n",
    "    output_file('Samples/Sample_Results/' ,filename, y_reduced_power, sr, '_pwr')\n",
    "    output_file('Samples/Sample_Results/' ,filename, y_reduced_mfcc_up, sr, '_mfcc_up')\n",
    "    output_file('Samples/Sample_Results/' ,filename, y_reduced_mfcc_down, sr, '_mfcc_down')\n",
    "    output_file('Samples/Sample_Results/' ,filename, y_reduced_median, sr, '_median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "py3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
